# "true" にすると GEMINI、"false" あるいは未設定で GPT 系を使います
LLM_USE_GEMINI=false

# LLM モデル名（GCP Gemini 用）
LLM_MODEL_GEMINI=gemini-2.0-flash

# LLM モデル名（OpenAI GPT 系）
# 例：gpt-4o、gpt-4、gpt-3.5-turbo
LLM_MODEL_GPT=gpt-3.5-turbo

# ──────────────────────────────────────────────
# 🌐 外部 VLM（HuggingFace など）設定
# ──────────────────────────────────────────────

# VLM プロバイダー名
# 例：huggingface、anthropic、azure_openai など
VLM_PROVIDER=huggingface

# VLM エンドポイント URL
VLM_BASE_URL=http://your_endpoint.aws.endpoints.huggingface.cloud/v1

# VLM API キー
VLM_API_KEY=hf_your_api_key

# VLM 上のモデル名
VLM_MODEL_NAME=your_model_name

# ──────────────────────────────────────────────
# 🔑 各種 API キー・認証トークン
# ──────────────────────────────────────────────

# OpenAI API Key（OpenAI SDK 使う場合）
# ※ VITE_ プレフィックスをつけるとフロントからも参照可能になります
VITE_OPENAI_API_KEY=sk...

# Hugging Face API Key（フロントで直接呼ぶ場合）
VITE_HF_API_KEY=hf-...

VITE_GEMINI_API_KEY =AIza...

# その他、必要なサービスの認証情報を追記してください
# EXAMPLE:
# THIRD_PARTY_SERVICE_API_KEY=...

# ──────────────────────────────────────────────
# 🛠 その他環境設定
# ──────────────────────────────────────────────

# NODE_ENV (development or production)
NODE_ENV=production
# アプリケーション固有の DB 名称（IndexedDB 等で使う場合）
# STORAGE_DB_NAME=my_app_db

# PORT（ローカル開発サーバーの起動ポート）
PORT=3000
