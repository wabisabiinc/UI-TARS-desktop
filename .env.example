# ────────────────────────────────────────
# LLM モデル切り替え設定（フロントで参照）
# ────────────────────────────────────────

# "true" にすると Gemini、"false" または未設定で GPT 系（OpenAI）を使います
VITE_LLM_USE_GEMINI=true

# GCP Gemini 用モデル名
VITE_LLM_MODEL_GEMINI=gemini-2.0-flash

# OpenAI GPT 系用モデル名
# 例：gpt-4o、gpt-4、gpt-3.5-turbo
VITE_LLM_MODEL_GPT=gpt-3.5-turbo

# ────────────────────────────────────────
# API キー（フロントで直接呼び出す場合）
# ────────────────────────────────────────

# OpenAI API Key
VITE_OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Gemini API Key
VITE_GEMINI_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Hugging Face API Key（Spaces 等をフロントで直接叩く場合）
VITE_HF_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ────────────────────────────────────────
# Node.js サーバー用環境変数
# ────────────────────────────────────────

# プロキシサーバー（server.mjs）で使うキー
GEMINI_API_KEY=${VITE_GEMINI_API_KEY}

# （必要なら）Hugging Face ベースURL／プロバイダー
# VLM_PROVIDER=huggingface
# VLM_BASE_URL=https://<your-hf-space>.hf.space/api
# VLM_API_KEY=${VITE_HF_API_KEY}
# VLM_MODEL_NAME=your_model_name

# ────────────────────────────────────────
# その他
# ────────────────────────────────────────

# NODE_ENV (development or production)
NODE_ENV=production

# IndexedDB などで使うストレージ名
STORAGE_DB_NAME=agent_tars_db

# ローカル開発サーバーのポート
PORT=3000
